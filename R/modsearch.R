##' @title Generate a list of \code{\linkS4class{ROCit}} objects or \code{\linkS4class{RMSE}} for different datasets
##' @param fit a \code{\linkS4class{train}} object generated by \code{\link{ROCtest}}
##' @param datatype a named character representing the accuracy object be built on either "train" or "test" data, 
##' user can include both
##' @param testdata a list of length two containing a named slot for the matrix of predictors 
##' (pred) and the vector of classes (class)
##' @param modelKeep a logical indicating whether the original model object should be stored, default is FALSE
##' @param ... additional arguments passed to \code{\link{modSearch}}
##' @return a list with the following:
##' \itemize{
##' \item{method - the \code{\link{train}} method used to fit the model}
##' \item{summaryTr - the \code{\linkS4class{ROCit}} for the training data}
##' \item{summaryTe - the \code{\linkS4class{ROCit}} for the test data}
##' \item{time - the time reported for the model to run, taken from the \code{\link{train}} object if available}
##' }
##' @note The values presented are for the optimal threshold as computed by the \code{\link{roc}} function.
##' @export
modAcc <- function(fit, datatype = c("test", "train"), testdata, modelKeep = FALSE, ...){
  if (missing(modelKeep)){
    modelKeep <- FALSE
  }
  if(fit$metric == "ROC"){
    if (length(datatype) > 1){
      train <- ROCtest(fit, ...)
      test <-  ROCtest(fit, testdata=list(preds = testdata$preds, 
                                          class = testdata$class), ...)    
    } else if(length(datatype) < 2 & datatype=="test"){
      test <- ROCtest(fit, testdata=list(preds = testdata$preds, 
                                         class = testdata$class), ...)
      train <- NULL
    } else if (length(datatype) < 2 & datatype=="train"){
      train <- ROCtest(fit, ...)
      test <- NULL
    }
  } else if(fit$metric == "RMSE"){
    if (length(datatype) > 1){
      train <- RMSEtest(fit)
      test <-  RMSEtest(fit, testdata=list(preds = testdata$preds, 
                                             class = testdata$class))    
    } else if(length(datatype) < 2 & datatype=="test"){
      test <- RMSEtest(fit, testdata=list(preds = testdata$preds, 
                                            class = testdata$class))
      train <- NULL
    } else if (length(datatype) < 2 & datatype=="train"){
      train <- RMSEtest(fit)
      test <- NULL
    }
  }
  if(modelKeep == TRUE){
    return(list(model=fit, summaryTr = train, summaryTe = test, method=fit$method, 
                time = fit$times$everything[3]))
  } else if(modelKeep == FALSE){
    return(list(method=fit$method, summaryTr = train, summaryTe = test, 
                time = fit$times$everything[3]))
  }
}

##' @title Generate a dataframe from \code{\link{modAcc}} lists
##' @description Used for generating the data to make good looking ROC curves of 
##' training and test data.
##' @param mod a list resulting from a call to \code{\link{modAcc}}
##' @return a \code{\link{data.frame}} with the following columns:
##' \itemize{
##' \item{sens - the sensitivities of the model at various thresholds}
##' \item{spec - the specificities of the model at various thresholds}
##' \item{grp - whether the model is using training or test data}
##' \item{method - the model method}
##' \item{auc - the area under the curve}
##' \item{elapsedTime - the time reported for the model to run}
##' }
##' @note The sensitivities and specificities come from the \code{\link{roc}} object stored in the 
##' \code{\linkS4class{ROCit}} object
##' @export 
dfExtract <- function(mod){
  if(class(mod$summaryTr) != "NULL"){
      newdatB <- data.frame(sens = smooth(mod$summaryTr@rocobj)$sensitivities, 
                            spec = smooth(mod$summaryTr@rocobj)$specificities, 
                            grp="train", 
                            auc = mod$summaryTr@auc,
                            method = mod$method, 
                            elapsedTime = ifelse(is.null(mod$time), NA, mod$time), 
                            check.rows=FALSE, 
                            row.names=NULL)
      }
    if(class(mod$summaryTe) != "NULL"){
      newdatA <- data.frame(sens = smooth(mod$summaryTe@rocobj)$sensitivities, 
                            spec = smooth(mod$summaryTe@rocobj)$specificities, 
                            grp="test",
                            auc  = mod$summaryTe@auc,
                            method = mod$method, 
                            elapsedTime =ifelse(is.null(mod$time), NA, mod$time), 
                            check.rows=FALSE, 
                            row.names=NULL)
      }    
    if(class(mod$summaryTr) != "NULL" & class(mod$summaryTe) != "NULL"){
      tmp <- rbind(newdatA, newdatB)
    } else if(class(mod$summaryTr) != "NULL"){
      tmp <- newdatB
    } else if(class(mod$summaryTe) != "NULL"){
      tmp <- newdatA
    }
    tmp$sens <- as.numeric(tmp$sens)
    tmp$spec <- as.numeric(tmp$spec)
    tmp$auc <- as.numeric(tmp$auc)
    tmp$method <- as.character(tmp$method)
    tmp$auc <- as.numeric(tmp$auc)
    tmp$grp <- as.character(tmp$grp)
    tmp$elapsedTime <- as.numeric(tmp$elapsedTime)
    return(tmp)
}

##' @title Train a model and store \code{\linkS4class{ROCit}} tests on different datasets
##' @description This function wraps the \code{train} function in the \code{caret} package with model accuracy reports. 
##' It also allows for errors in fitting models to be caught to make it easier to use in a loop. 
##' @param method a a string specifying which classification or regression model to use. Possible values are found using \code{names(getModelInfo())}. See http://caret.r-forge.r-project.org/bytag.html. A list of funciotns can also be passed for a custom model function. See http://caret.r-forge.r-project.org/custom_models.html for details
##' @param datatype a named character representing the accuracy object be built on either "train" or "test" data, 
##' user can include both
##' @param traindata a list of length two containing a named slot for the matrix of predictors 
##' (pred) and the vector of classes (class)
##' @param testdata a list of length two containing a named slot for the matrix of predictors 
##' (pred) and the vector of classes (class)
##' @param modelKeep a logical indicating whether the original model object should be stored
##' @param length an integer denoting the number of levels of each tuning parameter 
##' that should be generated to be passed to \code{tuneLength} in the \code{train} call
##' @param fitControl an object generated by \code{trainControl} to control the
##'  behavior of \code{train}. If none is given a default is selected.
##' @param metric a character string passed to \code{train}. a string that specifies what 
##' summary metric will be used to select the optimal model. By default, possible 
##' values are "RMSE" and "Rsquared" for regression and "Accuracy" and "Kappa" for 
##' classification. If custom performance metrics are used (via the \code{summaryFunction}
##' argument in trainControl, the value of metric should match one of the arguments. 
##' If it does not, a warning is issued and the first metric given by the 
##' summaryFunction is used. 
##' @param cores An integer representing the number of cores to use on Windows
##' @return A character string with an error if unsuccessful. The result of the \code{modAcc} call if successful: 
##' \itemize{
##' \item{method - the \code{\link{train}} method used to fit the model}
##' \item{summaryTr - the \code{\linkS4class{ROCit}} for the training data}
##' \item{summaryTe - the \code{\linkS4class{ROCit}} for the test data}
##' \item{time - the time reported for the model to run, taken from the \code{\link{train}} object if available}
##' }
##' @note The values presented are for the optimal threshold as computed by the \code{\link{roc}} function.
##' For some model types linear combos of predictors may be omitted.
##' @export
modTest <- function(method, datatype=c("train", "test"), traindata, testdata, 
                      modelKeep=FALSE, length, fitControl = NULL, 
                    metric = "ROC", cores = NULL){
  # Let's dump out some defaults
  # Set up cores for Windows
  if(!missing(cores)){
    myOS <- Sys.info()['sysname']
    if(myOS!="Windows") stop("Only declare cores on Windows machines. On Linux 
                             you can declare parallel outside of the modTest 
                             or modSearch call.")
    myclus <- makeCluster(cores) 
    registerDoParallel(myclus)
  }
  datD <- c('rda', 'lda2', 'hda', 'mda', 'mlp', 'mlpWeightDecay', 
            'rbf', 'rpart2', 'C5.0Rules', 'pda2', 'rda', 'glm',
            'treebag', 'rf', 'plr', 'lda', 'xyf', 'sddaLDA', 'sddaQDA', 
            'LogitBoost', 'C5.0', 'bag', 'C5.0Tree')
  if(method %in% datD){
    omit <- findLinearCombos(traindata$preds)$remove
    cols <- 1:ncol(traindata$preds)
    keep <- cols[!cols %in% omit]
    fit <- tryCatch({
      train(traindata$preds[, keep], traindata$class,
            method=method,
            trControl=fitControl,
            tuneLength = length, metric= metric)}, error = function(e) 
              message(paste0("Model failed to run: ", method)))
  } else {
    fit <- tryCatch({
      train(traindata$preds, traindata$class,
            method=method,
            trControl=fitControl,
            tuneLength = length, metric= metric)}, error = function(e) 
              message(paste0("Model failed to run: ", e)))
  }
  if(!missing(cores)){
    try(stopCluster(myclus))
    try(stopImplicitCluster())
  }
  if(class(fit) == "character"){
    message(paste0("Model failed to run: ", method))
    
  } else if(class(fit) == "train"){
      if(method %in% datD){
        fitSum <- modAcc(fit, datatype = datatype, 
                         testdata=list(preds = testdata$preds[, keep], 
                                       class = testdata$class ), 
                         modelKeep = modelKeep)
      } else {
        fitSum <- modAcc(fit, datatype = datatype, 
                         testdata = list(preds = testdata$preds, 
                                         class = testdata$class), 
                         modelKeep = modelKeep)
      }
      
    } 
  return(fitSum)
}

##' @title Generate an empty dataframe to match \code{\link{modAcc}} lists
##' @description Used for generating the data to make good looking ROC curves of 
##' training and test data.
##' @param methods a list of \code{train} method names to generate the dataframe for
##' @return a \code{\link{data.frame}} with the following columns:
##' \itemize{
##' \item{sens - the sensitivities of the model at various thresholds}
##' \item{spec - the specificities of the model at various thresholds}
##' \item{grp - whether the model is using training or test data}
##' \item{auc - the area under the curve}
##' \item{method - the model method}
##' \item{elapsedTime - the time reported for the model to run}
##' }
##' @note The sensitivities and specificities come from the \code{\link{roc}} object stored in the 
##' \code{\linkS4class{ROCit}} object
buildROCcurveFrame <- function(methods){
  ModelFits <- expand.grid(sens = NA, spec = NA, grp = NA, auc = NA, 
                           method = rep(methods, each = 1028), 
                           elapsedTime = NA)
  
  # Class variables correctly to avoid errors
  ModelFits$grp <- as.character(ModelFits$grp)
  ModelFits$method <- as.character(ModelFits$method)
  ModelFits$sens <- as.numeric(ModelFits$sens)
  ModelFits$spec <- as.numeric(ModelFits$spec)
  ModelFits$auc <- as.numeric(ModelFits$auc)
  return(ModelFits)
  
}

##' @title Generate an empty dataframe to match \code{\link{modAcc}} lists
##' @description Used for generating the data to make good looking ROC curves of 
##' training and test data.
##' @param methods a list of \code{train} method names to generate the dataframe for
##' @param ... additional arguments passed to \code{\link{modTest}}
##' @return a \code{\link{data.frame}} with the following columns:
##' \itemize{
##' \item{sens - the sensitivities of the model at various thresholds}
##' \item{spec - the specificities of the model at various thresholds}
##' \item{grp - whether the model is using training or test data}
##' \item{auc - the area under the curve}
##' \item{method - the model method}
##' \item{elapsedTime - the time reported for the model to run}
##' }
##' @note The sensitivities and specificities come from the \code{\link{roc}} object stored in the 
##' \code{\linkS4class{ROCit}} object
##' @export
##' 
modSearch <- function(methods, ...){
  ModelFits <- buildROCcurveFrame(methods)
  pb <- txtProgressBar(min = 0, max = length(methods), style = 3)
  args <- as.list(substitute(list(...)))[-1L]
  for(i in methods){
    p <- match(i, methods)
    z<-list(method = i)
    z<-c(z,args)
    fit <- try(do.call(modTest, z), silent = TRUE)
    tmp <- tryCatch(dfExtract(fit), error = function(e) "No Model Ran")
    #
    if(class(tmp) == "data.frame"){
      ModelFits[ModelFits$method == i,] <- tmp[tmp$method == i,]
    } else{
      ModelFits <- ModelFits
      message(paste(tmp, "failure for model type:", i, sep=" "))
    }
      setTxtProgressBar(pb, p)      
  }
  return(ModelFits)
}

# old block for timeout
# 
# if(!missing(timeout)){
#   timeout <- timeout
#   fit <- tryCatch({
#     evalWithTimeout({
#       do.call(modTest, z);
#     }, timeout = timeout, elapsed = timeout, onTimeout = "warning")},
#     TimeoutException = function(ex) {
#       print("Timeout. Skip")
#     }, error = function(e) {paste0("Failure of model: ", i, 
#                                    "\n", " For: ",e)})
#   
# } else if(missing(timeout)){
